{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests-html in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (2.32.3)\n",
      "Requirement already satisfied: pyquery in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (2.0.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (1.5.1)\n",
      "Requirement already satisfied: parse in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (1.20.2)\n",
      "Requirement already satisfied: bs4 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (0.0.2)\n",
      "Requirement already satisfied: w3lib in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (2.2.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests-html) (2.0.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2023 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (2024.6.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (8.0.0)\n",
      "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (11.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (4.66.4)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (1.26.19)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html) (10.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from bs4->requests-html) (4.12.3)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyquery->requests-html) (5.2.2)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyquery->requests-html) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests->requests-html) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from requests->requests-html) (3.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.19.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from beautifulsoup4->bs4->requests-html) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml_html_clean in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (0.1.1)\n",
      "Collecting lxml_html_clean\n",
      "  Downloading lxml_html_clean-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from lxml_html_clean) (5.2.2)\n",
      "Downloading lxml_html_clean-0.2.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "  Attempting uninstall: lxml_html_clean\n",
      "    Found existing installation: lxml_html_clean 0.1.1\n",
      "    Uninstalling lxml_html_clean-0.1.1:\n",
      "      Successfully uninstalled lxml_html_clean-0.1.1\n",
      "Successfully installed lxml_html_clean-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (4.22.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.19)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from selenium) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from selenium) (2024.6.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client>=1.8.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\documents\\personal\\scraper\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Requrements\n",
    "%pip install requests-html\n",
    "%pip install --upgrade lxml_html_clean\n",
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://bank-code.net/country/starts-with-letter-A', 'https://bank-code.net/country/starts-with-letter-B', 'https://bank-code.net/country/starts-with-letter-C', 'https://bank-code.net/country/starts-with-letter-D', 'https://bank-code.net/country/starts-with-letter-E', 'https://bank-code.net/country/starts-with-letter-F', 'https://bank-code.net/country/starts-with-letter-G', 'https://bank-code.net/country/starts-with-letter-H', 'https://bank-code.net/country/starts-with-letter-I', 'https://bank-code.net/country/starts-with-letter-J', 'https://bank-code.net/country/starts-with-letter-K', 'https://bank-code.net/country/starts-with-letter-L', 'https://bank-code.net/country/starts-with-letter-M', 'https://bank-code.net/country/starts-with-letter-N', 'https://bank-code.net/country/starts-with-letter-O', 'https://bank-code.net/country/starts-with-letter-P', 'https://bank-code.net/country/starts-with-letter-Q', 'https://bank-code.net/country/starts-with-letter-R', 'https://bank-code.net/country/starts-with-letter-S', 'https://bank-code.net/country/starts-with-letter-T', 'https://bank-code.net/country/starts-with-letter-U', 'https://bank-code.net/country/starts-with-letter-V', 'https://bank-code.net/country/starts-with-letter-W', 'https://bank-code.net/country/starts-with-letter-Y', 'https://bank-code.net/country/starts-with-letter-Z']\n"
     ]
    }
   ],
   "source": [
    "# Get all links containing countries bank-code.net\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "browser.get(\"https://bank-code.net/country/starts-with-letter-A\")\n",
    "# get list in <ul class=\"nav nav-pills\"></ul>\n",
    "ul = browser.find_element(By.CLASS_NAME, \"nav-pills\")\n",
    "# get list items in <li></li>\n",
    "lis = ul.find_elements(By.TAG_NAME, \"li\")\n",
    "# get links in <a></a>\n",
    "links = [li.find_element(By.TAG_NAME, \"a\") for li in lis]\n",
    "# get href attribute of <a></a>\n",
    "hrefs = [link.get_attribute(\"href\") for link in links]\n",
    "# print hrefs\n",
    "print(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.89)\nStacktrace:\n\tGetHandleVerifier [0x00007FF78CDA9632+30946]\n\t(No symbol) [0x00007FF78CD5E3C9]\n\t(No symbol) [0x00007FF78CC56FDA]\n\t(No symbol) [0x00007FF78CC2CB85]\n\t(No symbol) [0x00007FF78CCD37A7]\n\t(No symbol) [0x00007FF78CCEA771]\n\t(No symbol) [0x00007FF78CCCC813]\n\t(No symbol) [0x00007FF78CC9A6E5]\n\t(No symbol) [0x00007FF78CC9B021]\n\tGetHandleVerifier [0x00007FF78CEDF83D+1301229]\n\tGetHandleVerifier [0x00007FF78CEEBDB7+1351783]\n\tGetHandleVerifier [0x00007FF78CEE2A03+1313971]\n\tGetHandleVerifier [0x00007FF78CDDDD06+245686]\n\t(No symbol) [0x00007FF78CD6758F]\n\t(No symbol) [0x00007FF78CD63804]\n\t(No symbol) [0x00007FF78CD63992]\n\t(No symbol) [0x00007FF78CD5A3EF]\n\tBaseThreadInitThunk [0x00007FFF7E84257D+29]\n\tRtlUserThreadStart [0x00007FFF7FD4AF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m href \u001b[38;5;129;01min\u001b[39;00m hrefs:\n\u001b[0;32m      4\u001b[0m     browser\u001b[38;5;241m.\u001b[39mget(href)\n\u001b[1;32m----> 5\u001b[0m     divs \u001b[38;5;241m=\u001b[39m \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspan4Style\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# get second <a></a> for each <div></div>\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m div \u001b[38;5;129;01min\u001b[39;00m divs:\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Personal\\Scraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:778\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    774\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Personal\\Scraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Personal\\Scraper\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.89)\nStacktrace:\n\tGetHandleVerifier [0x00007FF78CDA9632+30946]\n\t(No symbol) [0x00007FF78CD5E3C9]\n\t(No symbol) [0x00007FF78CC56FDA]\n\t(No symbol) [0x00007FF78CC2CB85]\n\t(No symbol) [0x00007FF78CCD37A7]\n\t(No symbol) [0x00007FF78CCEA771]\n\t(No symbol) [0x00007FF78CCCC813]\n\t(No symbol) [0x00007FF78CC9A6E5]\n\t(No symbol) [0x00007FF78CC9B021]\n\tGetHandleVerifier [0x00007FF78CEDF83D+1301229]\n\tGetHandleVerifier [0x00007FF78CEEBDB7+1351783]\n\tGetHandleVerifier [0x00007FF78CEE2A03+1313971]\n\tGetHandleVerifier [0x00007FF78CDDDD06+245686]\n\t(No symbol) [0x00007FF78CD6758F]\n\t(No symbol) [0x00007FF78CD63804]\n\t(No symbol) [0x00007FF78CD63992]\n\t(No symbol) [0x00007FF78CD5A3EF]\n\tBaseThreadInitThunk [0x00007FFF7E84257D+29]\n\tRtlUserThreadStart [0x00007FFF7FD4AF28+40]\n"
     ]
    }
   ],
   "source": [
    "# for each href in hrefs get list of countries in <div class=\"span4Style\"></div>\n",
    "country_list_hrefs = []\n",
    "for href in hrefs:\n",
    "    browser.get(href)\n",
    "    divs = browser.find_elements(By.CLASS_NAME, \"span4Style\")\n",
    "    # get second <a></a> for each <div></div>\n",
    "    for div in divs:\n",
    "        as_ = div.find_elements(By.TAG_NAME, \"a\")[1]\n",
    "        country_list_hrefs.append(as_.get_attribute(\"href\"))\n",
    "print(country_list_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save country list hrefs to file so we can use it later\n",
    "with open(\"country_list_hrefs.txt\", \"w\") as file:\n",
    "    for href in country_list_hrefs:\n",
    "        file.write(href + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bank table from each page in #tableID\n",
    "# Get rows from table into object list\n",
    "# row contains 5 columns, No, Bank Name, Branch, City , Swift Code\n",
    "def getBankDetails(href):\n",
    "    browser.get(href)\n",
    "    table = browser.find_element(By.ID, \"tableID\").find_element(By.TAG_NAME, \"tbody\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    # print row data\n",
    "    bank_details = []\n",
    "    for row in rows:\n",
    "        data = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        # if data is not empty\n",
    "        if len(data) == 5:\n",
    "            bank_details.append({\n",
    "                \"BankName\": data[1].text,\n",
    "                \"Branch\": data[2].text,\n",
    "                \"City\": data[3].text,\n",
    "                \"SwiftCode\": data[4].text\n",
    "            })\n",
    "        else:\n",
    "            for d in data:\n",
    "                print(d.text)\n",
    "    return bank_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if page is paginated\n",
    "# for each country list href in country_list_hrefs check if element <nav aria-label=\"Page navigation\"></nav> exists\n",
    "#  if exists create list of hrefs \n",
    "# where if country_list_hrefs = https://bank-code.net/country/KENYA-%28KE%29.html\n",
    "# then hrefs = [ https://bank-code.net/country/KENYA-%28KE%29.html, https://bank-code.net/country/KENYA-%28KE%29/50.html, https://bank-code.net/country/KENYA-%28KE%29/100.html ... ]\n",
    "# else hrefs = [ https://bank-code.net/country/KENYA-%28KE%29.html ]\n",
    "\n",
    "def getBankTableList(country_list_href):\n",
    "    browser.get(country_list_href)\n",
    "    # check if pagination exists\n",
    "    try:\n",
    "        nav = browser.find_element(By.CLASS_NAME, \"pagination\")\n",
    "    except:\n",
    "        nav = None\n",
    "    hrefs = [country_list_href]\n",
    "    bank_details = []\n",
    "    if nav:\n",
    "        # generate links for 50 ... 100 ... 150 .... 1000\n",
    "        for i in range(1, 41):\n",
    "            # remove .html from country_list_href\n",
    "            country_list_href = country_list_href.replace(\".html\", \"\")\n",
    "            url = f\"{country_list_href}/{i * 50}.html\"\n",
    "            hrefs.append(url)\n",
    "        for href in hrefs:\n",
    "            bank_details.extend(getTableDataIfExists(href))\n",
    "    # return\n",
    "    print(\"Pages: \", bank_details)\n",
    "    return bank_details\n",
    "\n",
    "# check if url exists\n",
    "def getTableDataIfExists(url):\n",
    "    browser.get(url)\n",
    "    # url withouth .html matches current_url with .html return True else False\n",
    "    url_ = url\n",
    "    exists =  url.replace(\".html\", \"\") == browser.current_url.replace(\".html\", \"\")\n",
    "    if exists:\n",
    "        return getBankDetails(url_)\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "# check if file exists\n",
    "def checkIfFileExists(file):\n",
    "    try:\n",
    "        with open(file, \"r\") as f:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# create checked.txt file if not exists\n",
    "def createCheckedTxt():\n",
    "    if not checkIfFileExists(\"checked.txt\"):\n",
    "        with open(\"checked.txt\", \"w\") as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "# append href to checked.txt file\n",
    "def appendToChecked(href):\n",
    "    with open(\"checked.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(href + \"\\n\")\n",
    "\n",
    "# read checked.txt file\n",
    "def readChecked():\n",
    "    with open(\"checked.txt\", \"r\") as f:\n",
    "        return f.read().split(\"\\n\")\n",
    "\n",
    "# create bank details csv file if not exists\n",
    "def createBankDetailsCsv():\n",
    "    if not checkIfFileExists(\"bank_details.csv\"):\n",
    "        with open(\"bank_details.csv\", \"w\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"BankName\", \"Branch\", \"City\", \"SwiftCode\"])\n",
    "            writer.writeheader()\n",
    "\n",
    "# append bank details to csv file\n",
    "def appendToBankDetailsList(bank_details):\n",
    "    print(\"Appending \", bank_details)\n",
    "    with open(\"bank_details.csv\", \"a\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"BankName\", \"Branch\", \"City\", \"SwiftCode\"])\n",
    "        for bank_detail in bank_details:\n",
    "            writer.writerow(bank_detail)\n",
    "\n",
    "# get country list hrefs\n",
    "def getCountryListHrefs():\n",
    "    with open(\"country_list_hrefs.txt\", \"r\") as f:\n",
    "        return f.read().split(\"\\n\")\n",
    "\n",
    "createCheckedTxt()\n",
    "createBankDetailsCsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bank details for each href in country_list_hrefs\n",
    "# When href is checked add to checked list txt file\n",
    "# Save bank details to csv\n",
    "checked = readChecked()\n",
    "country_list_hrefs = getCountryListHrefs()\n",
    "for country_list_href in country_list_hrefs:\n",
    "    if country_list_href in checked:\n",
    "        continue\n",
    "    appendToBankDetailsList(getBankTableList(country_list_href))\n",
    "    appendToChecked(country_list_href)\n",
    "    checked.append(country_list_href)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
